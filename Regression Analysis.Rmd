---
title: "statistical Analyses"
output: html_document
editor_options:
  chunk_output_type: console
---

```{r setup, echo = FALSE, message=FALSE, results='hide'}
library(tidyverse)
library(COVID19)
library(lubridate)
library(modelr)
library(mgcv)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Create dataset with noaa data

The noaa dataset that we used was from the [https://www.ncdc.noaa.gov/cag/statewide/mapping](ncdc.noaa.gov) website. We retrieved 4 individual datasets from the noaa website. The retrieved dataset includes: 
1. tmax: Data for the maximum temperature for each state by month.
2. tmin: Data for the minimum temperature for each state by month. 
3. tavg: Data for the average temperaure for each state by month. 
4. prcp: Data for the precipitation values for each state by month. 

The datasets were scraped from the website using read_csv and were then merged with the COVID19 dataset by month and state. 

```{r creating dataset 1, echo = FALSE, message=FALSE, results='hide'}

tmin_df = read_csv("https://urldefense.proofpoint.com/v2/url?u=https-3A__www.ncdc.noaa.gov_cag_statewide_mapping_110-2Dtmin.csv&d=DwIFAg&c=G2MiLlal7SXE3PeSnG8W6_JBU6FcdVjSsBSbw6gcR0U&r=B8uzIkNMhKdWydN9xY4NUSbhsqKRbTFG_gmZY3kin8Q&m=ilRLcOY5-22-ot8YTUHjYK-tstakLha43P2L-7wwJSc&s=hmGOQjY_Ej_kzF9vStPclRFQpAr4mQSKOX5ce_tmlsE&e= ", skip = 3) %>%
  janitor::clean_names() %>%
   separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tmin = value) %>%
  filter(year == 2020) %>%
  select(state_name,state_code, month, state_tmin)

tmax_df = read_csv("https://urldefense.proofpoint.com/v2/url?u=https-3A__www.ncdc.noaa.gov_cag_statewide_mapping_110-2Dtmax.csv&d=DwIFAg&c=G2MiLlal7SXE3PeSnG8W6_JBU6FcdVjSsBSbw6gcR0U&r=B8uzIkNMhKdWydN9xY4NUSbhsqKRbTFG_gmZY3kin8Q&m=ilRLcOY5-22-ot8YTUHjYK-tstakLha43P2L-7wwJSc&s=kFXvvcnRWOVQuIlHG8ufptNh9-TGtc8HeymdMUmu_Dw&e= ", skip = 3) %>%
  janitor::clean_names() %>%
   separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tmax = value) %>%
  filter(year == 2020) %>%
  select(state_name,state_code, month, state_tmax)

tavg_df = read_csv("https://urldefense.proofpoint.com/v2/url?u=https-3A__www.ncdc.noaa.gov_cag_statewide_mapping_110-2Dtavg.csv&d=DwIFAg&c=G2MiLlal7SXE3PeSnG8W6_JBU6FcdVjSsBSbw6gcR0U&r=B8uzIkNMhKdWydN9xY4NUSbhsqKRbTFG_gmZY3kin8Q&m=ilRLcOY5-22-ot8YTUHjYK-tstakLha43P2L-7wwJSc&s=wY9iFojIMOK8mzQ7AkPJQDUUj3FfapibffutaytqzXU&e= ", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tavg = value) %>%
  filter(year == 2020) %>%
  select(state_name,state_code, month, state_tavg)

prcp_df = read_csv("https://urldefense.proofpoint.com/v2/url?u=https-3A__www.ncdc.noaa.gov_cag_statewide_mapping_110-2Dpcp.csv&d=DwIFAg&c=G2MiLlal7SXE3PeSnG8W6_JBU6FcdVjSsBSbw6gcR0U&r=B8uzIkNMhKdWydN9xY4NUSbhsqKRbTFG_gmZY3kin8Q&m=ilRLcOY5-22-ot8YTUHjYK-tstakLha43P2L-7wwJSc&s=VPeiJ1-NI637AZPZMfUV8exXyubpArhFG_u6KBXJlEI&e= ", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_total_prcp = value) %>%
  filter(year == 2020) %>%
  select(state_name,state_code, month, state_total_prcp)

noaa_dataset =
  inner_join(tavg_df, tmin_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code")) %>%
  inner_join(tmax_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code")) %>%
  inner_join(prcp_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code"))
write_csv(noaa_dataset,"data/noaa_dataset.csv")
```

## Import Covid datase. Clean and tidy data 

The COVID19 dataset was imported using the COVID19 R package. 
COVID-19 data was obtained from the `COVID19` package. This function has arguments set to return data at the state level. This dataset included information on the date, state, as well as the number of cases, tests, and hospitalizations for that given day. 

```{r creating dataset 2, echo = FALSE, message=FALSE, results='hide'}
#level = 2 gives state level data and raw = false cleans the dataset
covid_dataset = covid19(c("US"), level = 2, raw = FALSE, verbose = FALSE) %>%
  janitor::clean_names()

covid_data =
  covid_dataset %>%
  mutate(month = month(date),
         day = day(date),
         month = as.numeric(month),
         day = day(date)) %>%
  group_by(month, key_alpha_2) %>% top_n(1, day) %>%
  mutate(new_cases = confirmed - lag(confirmed, default = 0))

```

## Merging the two dataset 

```{r creating dataset 3, echo = FALSE, message=FALSE, results='hide'}
covid_noaa_dataset =
  inner_join(covid_data,noaa_dataset, by = c("key_alpha_2" = "state_code", "month" = "month")) %>%
  mutate(
    month_name = month(ymd(date), label = TRUE, abbr = FALSE)
  ) %>%
  rename(case_count = "confirmed")
write_csv(covid_noaa_dataset, "data/covid_noaa_dataset.csv" )
```

## Hypothesis

Our team hypothesizes that there is a relationship between temperature and COVID-19 cases.


### Relevant predictors

The following are the relevant predictors we want to include in the model

* `new_cases`- The number of new cases in every month.
* `case_count` - The total number of cases in every month.
* `population`- Total population of each state - This forms the offset variable in the poisson regression model and the demoninator for the count to extrapolate the rate.
* `state_name`- All the states in the USA
* `state_tavg`- The average temperature in a state in a month.
* `state_tmax`- The maximum temperature in a state in a month
* `state_tmin`- The minimum temperature in a state in a month
* `state_total_prcp` - The total precipitation in a state in a month.

### Assessing crude correlation among our selected variables

```{r correlation, echo = FALSE, message=FALSE, results='hide'}
library(MASS)
covid_noaa_dataset_cor =
covid_noaa_dataset %>%
  dplyr::select(new_cases, state_tavg, state_tmax, state_tmin, state_total_prcp)

  covid_noaa_dataset_cor[,3:7] %>%
  cor() %>%
  corrplot::corrplot(type = "lower",
                     method = "square",
                     addCoef.col = "red",
                     diag = FALSE,
                     number.cex = .6,
                     tl.col = "red",
                     tl.cex = .9,
                     tl.srt = 45)
  
```



### Confounding 

### Modeling - Poisson vs Negative binomial regression 


```{r regression model, echo = FALSE, message=FALSE, results='hide'}
poisson_mod = glm(new_cases ~  as.factor(month) + state_tavg + state_total_prcp, 
                    family = "poisson"(link = "log"), data = covid_noaa_dataset)

poisson_mod %>%
  broom::glance() %>% 
  dplyr::select(AIC) %>% 
  knitr::kable(digits = 3)

neg_bin_mod = glm.nb(new_cases ~ as.factor(month) + state_tavg + state_total_prcp,
                            data = covid_noaa_dataset)

neg_bin_mod %>% 
  broom::glance() %>% 
  dplyr::select(AIC) %>% 
  knitr::kable(digits = 3)
```
Since the AIC for Poisson is 28597532 and the AIC for negative binomia regression model is 9174.884, we decided to proceed with negative binomial regression model 

## Cross validation 


```{r cross validation, echo = FALSE, message=FALSE, results='hide'}
count_cv = 
  crossv_mc(covid_noaa_dataset, 100)
count_cv = 
  count_cv %>% 
  mutate(  
    model_poisson = map(train, ~glm(new_cases ~  as.factor(month) + state_tavg + state_total_prcp,
                                    family="poisson" (link = log), covid_noaa_dataset)), 
    model_neg_binomial = map(train, ~ glm.nb(new_cases ~  as.factor(month) + state_tavg + state_total_prcp, 
                                             data = covid_noaa_dataset))) %>% 
  mutate(rmse_poisson = map2_dbl(model_poisson, test, ~rmse(model = .x, data = .y)), 
         rmse_negative_binomial = map2_dbl(model_neg_binomial, test, ~rmse(model = .x, data = .y)))

count_cv %>% 
  dplyr::select(rmse_poisson, rmse_negative_binomial) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "Prediction Error Distributions"
  )
```




