---
title: "Statistical Analyses"
output: html_document
editor_options:
  chunk_output_type: console
---

```{r setup, echo = FALSE, message=FALSE, results='hide'}
library(tidyverse)
library(COVID19)
library(lubridate)
library(modelr)
library(mgcv)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Create dataset with noaa data

The noaa dataset that we used was from the [ncdc.noaa.gov](https://www.ncdc.noaa.gov/cag/statewide/mapping) website. We retrieved 4 individual datasets from the noaa website. The retrieved dataset includes:
1. tmax: Data for the maximum temperature for each state by month.
2. tmin: Data for the minimum temperature for each state by month.
3. tavg: Data for the average temperaure for each state by month.
4. prcp: Data for the precipitation values for each state by month.

The datasets were scraped from the website using read_csv and were then merged with the COVID19 dataset by month and state.

```{r creating dataset 1, echo = FALSE, message=FALSE, results='hide'}

tmin_df = read_csv("./data/110-tmin.csv", skip = 3) %>%
  janitor::clean_names() %>%
   separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tmin = value) %>%
  filter(year == 2020) %>%
  dplyr::select(state_name,state_code, month, state_tmin)

tmax_df = read_csv("./data/110-tmax.csv", skip = 3) %>%
  janitor::clean_names() %>%
   separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tmax = value) %>%
  filter(year == 2020) %>%
  dplyr::select(state_name,state_code, month, state_tmax)

tavg_df = read_csv("./data/110-tavg.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_tavg = value) %>%
  filter(year == 2020) %>%
  dplyr::select(state_name,state_code, month, state_tavg)

prcp_df = read_csv("./data/110-pcp.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    month = as.numeric(month),
    state_code = state.abb[match(location,state.name)],
    state_name = location,
    state_total_prcp = value) %>%
  filter(year == 2020) %>%
  dplyr::select(state_name,state_code, month, state_total_prcp)

noaa_dataset =
  inner_join(tavg_df, tmin_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code")) %>%
  inner_join(tmax_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code")) %>%
  inner_join(prcp_df, by = c("state_name" = "state_name", "month" = "month", "state_code" = "state_code"))
write_csv(noaa_dataset,"data/noaa_dataset.csv")
```

## Import Covid datase. Clean and tidy data

The COVID19 dataset was imported using the COVID19 R package.
COVID-19 data was obtained from the `COVID19` package. This function has arguments set to return data at the state level. This dataset included information on the date, state, as well as the number of cases, tests, and hospitalizations for that given day.

```{r creating dataset 2, echo = FALSE, message=FALSE, results='hide'}
#level = 2 gives state level data and raw = false cleans the dataset
covid_dataset = covid19(c("US"), level = 2, raw = FALSE, verbose = FALSE) %>%
  janitor::clean_names()

covid_data =
  covid_dataset %>%
  mutate(month = month(date),
         day = day(date),
         month = as.numeric(month),
         day = day(date)) %>%
  group_by(month, key_alpha_2) %>% top_n(1, day) %>%
  mutate(new_cases = confirmed - lag(confirmed, default = 0))

```

## Merging the two dataset

```{r creating dataset 3, echo = FALSE, message=FALSE, results='hide'}
covid_noaa_dataset =
  inner_join(covid_data,noaa_dataset, by = c("key_alpha_2" = "state_code", "month" = "month")) %>%
  mutate(
    month_name = month(ymd(date), label = TRUE, abbr = FALSE)
  ) %>%
  rename(case_count = "confirmed", state = "key_alpha_2")
write_csv(covid_noaa_dataset, "data/covid_noaa_dataset.csv" )
```

## Hypothesis

Our team hypothesizes that the relationship between temperature and COVID-19 cases are correlated. We have looked at the trends in COVID and Climate in the United States between Jan 2020 and October 2020. *Include a plot here of covid cases vs temperature* Check out our interactive map here "*insert link to Maya and Michelle's map*. We want to conduct an analysis to see if cases increase with increase in temperature.

### Relevant predictors

The following are the relevant predictors we want to include in the model

* `new_cases`- The number of new cases in every month.
* `case_count` - The total number of cases in every month.
* `population`- Total population of each state - This forms the offset variable in the poisson regression model and the demoninator for the count to extrapolate the rate.
* `state_name`- All the states in the USA
* `state_tavg`- The average temperature in a state in a month.
* `state_tmax`- The maximum temperature in a state in a month
* `state_tmin`- The minimum temperature in a state in a month
* `state_total_prcp` - The total precipitation in a state in a month.

### Assessing crude correlation among our selected variables

```{r correlation, echo = FALSE, message=FALSE, results='hide'}
library(MASS)
covid_noaa_dataset_cor =
covid_noaa_dataset %>%
  dplyr::select(new_cases, state_tavg, state_tmax, state_tmin, state_total_prcp)

  covid_noaa_dataset_cor[,3:7] %>%
  cor() %>%
  corrplot::corrplot(type = "lower",
                     method = "square",
                     addCoef.col = "red",
                     diag = FALSE,
                     number.cex = .6,
                     tl.col = "red",
                     tl.cex = .9,
                     tl.srt = 45,
                     is.corr = FALSE)
 
```

In order to select the most significant variables in our model we first conducted a crude correlation assessment using a correlation matrix as shown above. From this assessment we decided to remove `state_tmax` and `state_tmin` since the r is 0.97 - 0.99, indicating that there is an extreme co-linearity among other predictors.

### Confounding

There are many variables that would confound the relationship between temperature and case count. We have included ones that we felt are the most important. However, in order to maintain parsimonious model we restricted the number of predictors. This could also be a limitation of our model.

### Modeling - Poisson vs Negative binomial regression

Our outcome variable is a count variable, hence we want to model either a poisson regression or a negative binomial regression. 

A poisson distribution assumes that the mean and variance are the same. Sometimes the data shows extra variation that is greater than the mean. This situation is called overdispersion. Negative binomial is more flexible in that regard.
Negative binomial has one more parameter the adjusts for the variance independently from the mean. 

In order to decide which model to use we cross validate between the two models to see the distribution. We also assess the AIC to determine the model with the smaller AIC.

```{r regression model, echo = FALSE, message=FALSE, results='hide'}
poisson_mod = glm(new_cases ~  as.factor(month_name) + state + state_tavg + state_total_prcp,
                    family = "poisson"(link = "log"), data = covid_noaa_dataset)

poisson_mod %>%
  broom::glance() %>%
  dplyr::select(AIC) %>%
  knitr::kable(digits = 3)

neg_bin_mod = glm.nb(new_cases ~ as.factor(month_name) + state + state_tavg + state_total_prcp,
                            data = covid_noaa_dataset)

neg_bin_mod %>%
  broom::glance() %>%
  dplyr::select(AIC) %>%
  knitr::kable(digits = 3)
```


## Cross validation


```{r cross validation, echo = FALSE, message=FALSE, results='hide'}
count_cv =
  crossv_mc(covid_noaa_dataset, 100)
count_cv =
  count_cv %>%
  mutate(  
    model_poisson = map(train, ~glm(new_cases ~  as.factor(month) + state + state_tavg + state_total_prcp,
                                    family="poisson" (link = log), covid_noaa_dataset)),
    model_neg_binomial = map(train, ~ glm.nb(new_cases ~  as.factor(month) + state + state_tavg + state_total_prcp,
                                             data = covid_noaa_dataset))) %>%
  mutate(rmse_poisson = map2_dbl(model_poisson, test, ~rmse(model = .x, data = .y)),
         rmse_negative_binomial = map2_dbl(model_neg_binomial, test, ~rmse(model = .x, data = .y)))

count_cv %>%
  dplyr::select(rmse_poisson, rmse_negative_binomial) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "Prediction Error Distributions"
  )
```

From the distribution above we can see that both the figures are very similar to each other. We cannot solely base our decision to use either of the models based on this distribution. Hence we look at the AIC. 

The poisson model has an AIC of 
The negative binomial model has an AIC of 

Since the Negative binomial model has a smaller AIC than the poission model we chose the negative binomial model.

```{r}
nb_output = neg_bin_mod %>%
  broom::tidy() %>%
  dplyr::select(term, estimate, p.value) %>%
  mutate(exp(estimate)) 

nb_output %>% 
  knitr::kable(digits = 3)
```

```{r}
write_csv(covid_noaa_dataset, "Predictive_Interactive_map/covid_noaa_dataset.csv" )
```

## Model 2 

### Data for Model 2 

```{r creating data 3, echo = FALSE, message=FALSE, results='hide'}
ct_school_work_gather = 
  covid_noaa_dataset %>%
  dplyr::select(date, case_count, new_cases, population, school_closing, workplace_closing, gatherings_restrictions, state, state_name, state_tavg, month_name)
```

### Hypothesis

In our initial hypotheses we have established that there is a relationship between temperature and COVID-19 cases. We now want to see if this relationship would change with certain events such as school closures, workplace closures and gathering. 

### Relevant predictors

The following are the relevant predictors we want to include in the model

* `new_cases`- The number of new cases in every month.
* `case_count` - The total number of cases in every month.
* `population`- Total population of each state - This forms the offset variable in the poisson regression model and the demoninator for the count to extrapolate the rate.
* `state_name`- All the states in the USA
* `state_tavg`- The average temperature in a state in a month.
* `school_closing`- 0: No measures - 1: Recommend closing - 2: Require closing (only some levels or categories, eg just high school, or just public schools - 3: Require closing all levels.
* `workplace_closing`- 0: No measures - 1: Recommend closing (or work from home) - 2: require closing for some sectors or categories of workers - 3: require closing (or work from home) all-but-essential workplaces (eg grocery stores, doctors).
* `gatherings_restriction` - 0: No restrictions - 1: Restrictions on very large gatherings (the limit is above 1000 people) - 2: Restrictions on gatherings between 100-1000 people - 3: Restrictions on gatherings between 10-100 people - 4: Restrictions on gatherings of less than 10 people.

